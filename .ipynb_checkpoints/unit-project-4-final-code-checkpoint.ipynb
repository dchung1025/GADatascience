{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SF-DAT-21 | Unit Project 4\n",
    "\n",
    "In this project, you will summarize and present your analysis from Unit Projects 1-3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1. Introduction: Write a problem Statement/Specific Aim for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Based on UCLA graduate school applicant's GPA, GRE score, and prestige of college attended, can we predict whether the candidate will be admitted into the UCLA graduate program. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2. Dataset: Write up a description of your data and any cleaning that was completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "Data is made up of 4 variables (listed below):\n",
    "\n",
    "Variable | Description | Type of Variable\n",
    "---|---|---\n",
    "admit | 0 = Not Admitted, 1 = Admitted | Categorical\n",
    "gre | gre score | Continuous (integer)\n",
    "gpa | gpa score out of 4.0 | Continuous (float)\n",
    "prestige | how prestigous is applicant alma mater (1= high, 4 = low) | Categorial (integer)\n",
    "\n",
    "There were 3 data points that were excluded because they had NaN values for GPA, GRE, or prestige. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 3. Demo: Provide a table that explains the data by admission status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean (STD) or counts by admission status for each variable\n",
    "\n",
    "| Not Admitted | Admitted\n",
    "---| ---|---\n",
    "GPA | 3.34 (.37) | 3.48 (.37)\n",
    "GRE | 573 (116) | 618 (109)\n",
    "Prestige 1 | 28 (10%) | 33 (26%)\n",
    "Prestige 2 | 95 (35%) | 53 (42%)\n",
    "Prestige 3 | 93 (35%) | 28 (22%)\n",
    "Prestige 4 | 55 (20%) | 12 (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4. Methods: Write up the methods used in your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "I decided to split the dataset 60% as a training dataset and 40% as the test dataset to do some validations after I create a Logistic Regression model for the data. \n",
    "\n",
    "First, I added an intercept field into the dataset and then use the covariates 'gpa', 'gre', 'prestige_2', 'prestige_3', and 'prestige_4' to create a Logistic Regression Model. \n",
    "\n",
    "Initially, I tried to include a interaction between gpa and gre, but the resulting accuracy and overall score of the model was lower than without the interaction effect added so decided to exclude the interaction effect in the Logistic Regression. \n",
    "\n",
    "After running a Logistic Regression on the training set and with a result that seemed pretty good (with a result of 72% accuracy), I ran a prediction using the model created from the Logistic Regression, inputing the test dataset as the variables this time. Then I compared the results of my predictio against the actual admission outcome of the test dataset to test the accuracy of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5. Results: Write up your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "Initially, the model showed an accuracy of 72% which seemed pretty good, but on looking at the actual results of admission of the total dataset, you see that 66% of people were rejected from UCLA. What this is saying is that if we just decided to guess that everyone is rejected in a test set, we'd have 66% accuracy. So the model is only slightly better than the state we were at before the model was created. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6. Visuals: Provide a table or visualization of these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='asset/pic 1.png' height= 25% width= 25%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='asset/pic 2.png' height= 25% width= 25%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### question 7. Discussion: Write up your discussion and future steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Overall, the model was a slight improvement vs. pre-model, but I would perhaps look for another way of creating some kind of interactions across the four categories because from my perspective, the admission doesn't simply look at each category individually, but holistcally. \n",
    "\n",
    "Another thing to perhaps look at is looking to add additional datapoints. Perhaps we can find extracurriculars of the applicants and perhaps we can look at ethnicity as well. \n",
    "\n",
    "Lastly, I can look at a different model, perhaps looking at using a decision tree regressor or a random forest to predict admission might work as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
